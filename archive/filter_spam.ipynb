{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from config import presidents, cities, countries\n",
    "data_path = os.environ['DATAPATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bigram_similarity(bigrams1, bigrams2):\n",
    "    \"\"\"Calculate bi-gram similarity using precomputed bigrams.\"\"\"\n",
    "    intersection = sum((bigrams1 & bigrams2).values())\n",
    "    total = sum(bigrams1.values()) + sum(bigrams2.values()) - intersection\n",
    "    return intersection / total if total else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def generate_word_bigrams(text):\n",
    "    words = text.split()  # Split the text into words\n",
    "    return [tuple(words[i:i+2]) for i in range(len(words) - 1)]  # Generate word bi-grams\n",
    "\n",
    "def calculate_bigram_similarity(text1, text2, letter_bigrams=False):\n",
    "    if letter_bigrams:\n",
    "        # Generate bigrams for each string\n",
    "        bigrams1 = [text1[i:i+2] for i in range(len(text1)-1)]\n",
    "        bigrams2 = [text2[i:i+2] for i in range(len(text2)-1)]\n",
    "    else: \n",
    "        # word bigrams\n",
    "        # Generate word bi-grams for each string\n",
    "        bigrams1 = generate_word_bigrams(text1)\n",
    "        bigrams2 = generate_word_bigrams(text2)\n",
    "\n",
    "    # Count bigrams\n",
    "    bigrams1_count = Counter(bigrams1)\n",
    "    bigrams2_count = Counter(bigrams2)\n",
    "\n",
    "    # Calculate intersection and total\n",
    "    intersection = sum((bigrams1_count & bigrams2_count).values())\n",
    "    total = sum(bigrams1_count.values()) + sum(bigrams2_count.values()) - intersection\n",
    "\n",
    "    return intersection / total if total else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Convert text to lowercase.\"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "def filter_spam_tweets(data):\n",
    "    non_spam_data = pd.DataFrame()\n",
    "    users_to_drop = set()\n",
    "\n",
    "    for user_id, group in data.groupby('item_number'):\n",
    "        if user_id in users_to_drop:\n",
    "            continue\n",
    "\n",
    "        # Preprocess tweets to lowercase before comparison\n",
    "        tweets = [preprocess_text(text) for text in group['text'].tolist()]\n",
    "        spam_found = False\n",
    "\n",
    "        for i in range(len(tweets)):\n",
    "            for j in range(i + 1, len(tweets)):\n",
    "                similarity = calculate_bigram_similarity(tweets[i], tweets[j], letter_bigrams=False)\n",
    "                if similarity > 0.8:\n",
    "                    users_to_drop.add(user_id)\n",
    "                    spam_found = True\n",
    "                    break\n",
    "            if spam_found:\n",
    "                break\n",
    "\n",
    "        if not spam_found:\n",
    "            non_spam_data = pd.concat([non_spam_data, group], ignore_index=True)\n",
    "\n",
    "    return data[~data['item_number'].isin(users_to_drop)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exectuion was manually stopped after 689m 39.8s because runtime was too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for president in presidents:\n",
    "    data = pd.read_pickle(f'{data_path}{president}.pkl')\n",
    "    data_filtered = filter_spam_tweets(data)\n",
    "    data_filtered.to_pickle(f'{data_path}{president}-filtered.pkl')\n",
    "    print(f\"{president.capitalize()}: {data.shape[0]} -> {data_filtered.shape[0]} | Filtered: {data.shape[0] - data_filtered.shape[0]} Tweets\")\n",
    "    for location in countries + cities:\n",
    "        data = pd.read_pickle(f'{data_path}{president}-{location}.pkl')\n",
    "        data_filtered = filter_spam_tweets(data)\n",
    "        data_filtered.to_pickle(f'{data_path}{president}-{location}-filtered.pkl')\n",
    "        print(f\"{president.capitalize()} - {location}: {data.shape[0]} -> {data_filtered.shape[0]} | Filtered: {data.shape[0] - data_filtered.shape[0]} Tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  User Tweet Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_tweet_counts(president):\n",
    "    data = pd.read_pickle(f'{data_path}{president}.pkl')\n",
    "    tweet_counts = data.groupby('user_id').size().reset_index(name='tweet_count')\n",
    "    tweet_counts.sort_values('tweet_count', ascending=False, inplace=True)\n",
    "\n",
    "    return tweet_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_user_tweet_counts = user_tweet_counts(presidents[0])\n",
    "johnson_user_tweet_counts = user_tweet_counts(presidents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_number</th>\n",
       "      <th>tweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184303</th>\n",
       "      <td>226628</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_number  tweet_count\n",
       "184303       226628           11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_user_tweet_counts[trump_user_tweet_counts['tweet_count']>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def visualize_high_frequency_tweeters(tweet_counts):\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(tweet_counts['item_number'].astype(str), tweet_counts['tweet_count'], color='skyblue')\n",
    "    plt.xlabel('User ID')\n",
    "    plt.ylabel('Tweet Count')\n",
    "    plt.title('Tweet Counts per User')\n",
    "    plt.xticks(rotation=90, fontsize=8)  # Rotate x-axis labels for better readability\n",
    "    plt.tight_layout()  # Adjust layout to make room for the rotated x-axis labels\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Frequency of Posts in a Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def users_with_high_activity(president):\n",
    "    data = pd.read_pickle(f'{data_path}{president}.pkl')\n",
    "    # Ensure 'date' is in datetime format and 'item_number' represents user ID\n",
    "    data['date'] = pd.to_datetime(data['date']).dt.date\n",
    "    high_activity_users = data.groupby(['item_number', 'date']).filter(lambda x: len(x) > 10)\n",
    "    return high_activity_users['item_number'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load users with high activity\n",
    "trump_high_activity_users = users_with_high_activity(presidents[0])\n",
    "johnson_high_activity_users = users_with_high_activity(presidents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_high_activity_users_tweets(president):\n",
    "    data = pd.read_pickle(f'{data_path}{president}.pkl')\n",
    "    # Ensure 'date' is in datetime format\n",
    "    data['date'] = pd.to_datetime(data['date']).dt.date\n",
    "    # Identify users with more than 10 tweets in any single day\n",
    "    high_activity_users = data.groupby(['item_number', 'date']).filter(lambda x: len(x) > 10)['item_number'].unique()\n",
    "    # Filter out tweets from high activity users\n",
    "    return data[~data['item_number'].isin(high_activity_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data\n",
    "trump_filtered = remove_high_activity_users_tweets(presidents[0])\n",
    "johnson_filtered = remove_high_activity_users_tweets(presidents[1])\n",
    "# save data\n",
    "trump_filtered.to_pickle(f'{data_path}trump.pkl')\n",
    "johnson_filtered.to_pickle(f'{data_path}johnson.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
