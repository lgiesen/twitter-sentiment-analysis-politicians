{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from main import get_data\n",
    "(root, data_path, presidents, cities, countries, years, colors) = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bigram_similarity(bigrams1, bigrams2):\n",
    "    \"\"\"Calculate bi-gram similarity using precomputed bigrams.\"\"\"\n",
    "    intersection = sum((bigrams1 & bigrams2).values())\n",
    "    total = sum(bigrams1.values()) + sum(bigrams2.values()) - intersection\n",
    "    return intersection / total if total else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def generate_word_bigrams(text):\n",
    "    words = text.split()  # Split the text into words\n",
    "    return [tuple(words[i:i+2]) for i in range(len(words) - 1)]  # Generate word bi-grams\n",
    "\n",
    "def calculate_bigram_similarity(text1, text2, letter_bigrams=False):\n",
    "    if letter_bigrams:\n",
    "        # Generate bigrams for each string\n",
    "        bigrams1 = [text1[i:i+2] for i in range(len(text1)-1)]\n",
    "        bigrams2 = [text2[i:i+2] for i in range(len(text2)-1)]\n",
    "    else: \n",
    "        # word bigrams\n",
    "        # Generate word bi-grams for each string\n",
    "        bigrams1 = generate_word_bigrams(text1)\n",
    "        bigrams2 = generate_word_bigrams(text2)\n",
    "\n",
    "    # Count bigrams\n",
    "    bigrams1_count = Counter(bigrams1)\n",
    "    bigrams2_count = Counter(bigrams2)\n",
    "\n",
    "    # Calculate intersection and total\n",
    "    intersection = sum((bigrams1_count & bigrams2_count).values())\n",
    "    total = sum(bigrams1_count.values()) + sum(bigrams2_count.values()) - intersection\n",
    "\n",
    "    return intersection / total if total else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Convert text to lowercase.\"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "def filter_spam_tweets(data):\n",
    "    non_spam_data = pd.DataFrame()\n",
    "    users_to_drop = set()\n",
    "\n",
    "    for user_id, group in data.groupby('item_number'):\n",
    "        if user_id in users_to_drop:\n",
    "            continue\n",
    "\n",
    "        # Preprocess tweets to lowercase before comparison\n",
    "        tweets = [preprocess_text(text) for text in group['text'].tolist()]\n",
    "        spam_found = False\n",
    "\n",
    "        for i in range(len(tweets)):\n",
    "            for j in range(i + 1, len(tweets)):\n",
    "                similarity = calculate_bigram_similarity(tweets[i], tweets[j], letter_bigrams=False)\n",
    "                if similarity > 0.8:\n",
    "                    users_to_drop.add(user_id)\n",
    "                    spam_found = True\n",
    "                    break\n",
    "            if spam_found:\n",
    "                break\n",
    "\n",
    "        if not spam_found:\n",
    "            non_spam_data = pd.concat([non_spam_data, group], ignore_index=True)\n",
    "\n",
    "    return data[~data['item_number'].isin(users_to_drop)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for president in presidents:\n",
    "    data = pd.read_pickle(f'{data_path}{president}.pkl')\n",
    "    data_filtered = filter_spam_tweets(data)\n",
    "    data_filtered.to_pickle(f'{data_path}{president}-filtered.pkl')\n",
    "    print(f\"{president.capitalize()}: {data.shape[0]} -> {data_filtered.shape[0]} | Filtered: {data.shape[0] - data_filtered.shape[0]} Tweets\")\n",
    "    for location in countries + cities:\n",
    "        data = pd.read_pickle(f'{data_path}{president}-{location}.pkl')\n",
    "        data_filtered = filter_spam_tweets(data)\n",
    "        data_filtered.to_pickle(f'{data_path}{president}-{location}-filtered.pkl')\n",
    "        print(f\"{president.capitalize()} - {location}: {data.shape[0]} -> {data_filtered.shape[0]} | Filtered: {data.shape[0] - data_filtered.shape[0]} Tweets\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
